import os
import json
import base64
import time
from openai import OpenAI

# ================= é…ç½®éƒ¨åˆ† =================

# APIé…ç½®ï¼ŒæŒ‰æ¨¡å‹æä¾›å•†åˆ†ç±»
API_CONFIGS = {
    "aliyun": {
        "api_key": "sk-7e6b3a62b1f64945a5a4a9347afa5c72",
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
    },
    "siliconflow": {
        "api_key": "sk-izrxbwrnxotwsvcngnnmwivxmyqukrivnjcoszzpscmfasjz",
        "base_url": "https://api.siliconflow.cn/v1"
    }
}

# é…ç½®è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
TEST_MODELS = [
    # é˜¿é‡Œäº‘æ¨¡å‹
    "qwen-vl-max-latest",
    "qwen3-vl-plus",
    "qwen3-vl-flash",
    # SiliconFlowæ¨¡å‹
    "Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "zai-org/GLM-4.6V"
]

# æ¨¡å‹åˆ°APIæä¾›å•†çš„æ˜ å°„
MODEL_TO_API = {
    "qwen3-vl-plus": "aliyun",
    "qwen3-vl-flash": "aliyun",
    "qwen-vl-max-latest": "aliyun",
    "Qwen/Qwen3-Omni-30B-A3B-Instruct": "siliconflow",
    "zai-org/GLM-4.6V": "siliconflow",
    "Qwen/Qwen3-VL-30B-A3B-Instruct": "siliconflow"
}

# é»˜è®¤é…ç½®
DEFAULT_VIDEO_PATH = "t2v_videos\\Projector_(æŠ•å½±ä»ª)_SFX_1.mp4"
DEFAULT_QUESTION = "Summarize the video."

# ================= è¾…åŠ©å‡½æ•° =================

def compress_video_smart(video_path, target_size_mb=7.0):
    """
    æ™ºèƒ½å‹ç¼©è§†é¢‘ï¼šå¦‚æœè§†é¢‘è¶…è¿‡ç›®æ ‡å¤§å°ï¼Œåˆ™é€šè¿‡é™ä½å¸§ç‡æ¥å‹ç¼©ï¼Œ
    åŒæ—¶ä¿æŒç”»è´¨ï¼ˆCRF 18ï¼‰ä¸å˜ã€‚
    
    è¿”å›: (æ–‡ä»¶è·¯å¾„, æ˜¯å¦æ˜¯ä¸´æ—¶æ–‡ä»¶)
    """
    if not os.path.exists(video_path):
        return video_path, False

    file_size = os.path.getsize(video_path) / (1024 * 1024)
    
    # å¦‚æœå°äºç›®æ ‡å¤§å°ï¼Œç›´æ¥è¿”å›
    if file_size <= target_size_mb:
        return video_path, False

    print(f"ğŸ“¦ Video {os.path.basename(video_path)} is {file_size:.2f}MB. Compressing to < {target_size_mb}MB...")
    
    temp_path = video_path.replace(".mp4", "_compressed_temp.mp4")
    
    # ç­–ç•¥ï¼šé™ä½å¸§ç‡ï¼Œä½†ä¿æŒé«˜è´¨é‡
    target_fps = "5" 
    
    # å¦‚æœæ–‡ä»¶ç‰¹åˆ«å¤§ (>30MB)ï¼Œå°è¯•é™ä½åˆ° 3fps
    if file_size > 30:
        target_fps = "3"

    cmd = [
        "ffmpeg", "-y",                # è¦†ç›–è¾“å‡º
        "-i", video_path,              # è¾“å…¥
        "-r", target_fps,              # ç›®æ ‡å¸§ç‡
        "-c:v", "libx264",             # ç¼–ç å™¨
        "-pix_fmt", "yuv420p",         # å¼ºåˆ¶ä½¿ç”¨ yuv420p åƒç´ æ ¼å¼
        "-crf", "18",                  # æ’å®šè´¨é‡å› å­ (18=é«˜ç”»è´¨/è§†è§‰æ— æŸ)
        "-preset", "veryfast",         # ç¼–ç é€Ÿåº¦
        "-an",                         # ç§»é™¤éŸ³é¢‘
        temp_path
    ]
    
    try:
        # æ‰§è¡Œå‹ç¼©ï¼Œé™é»˜è¾“å‡º
        import subprocess
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        
        # æ£€æŸ¥å‹ç¼©åçš„å¤§å°
        new_size = os.path.getsize(temp_path) / (1024 * 1024)
        
        # å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œå°è¯•è¿›ä¸€æ­¥å‹ç¼©
        if new_size > target_size_mb:
            print(f"âš ï¸ Still too large ({new_size:.2f}MB). Re-compressing aggressively...")
            cmd_aggressive = [
                "ffmpeg", "-y", "-i", video_path,
                "-r", "2", "-c:v", "libx264",
                "-pix_fmt", "yuv420p",
                "-crf", "23", "-preset", "veryfast", "-an",
                temp_path
            ]
            subprocess.run(cmd_aggressive, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
            new_size = os.path.getsize(temp_path) / (1024 * 1024)

        print(f"âœ… Compressed to {new_size:.2f}MB (FPS: {target_fps})")
        return temp_path, True
        
    except Exception as e:
        print(f"âŒ Compression failed (ffmpeg might be missing): {e}. Using original.")
        if os.path.exists(temp_path):
            os.remove(temp_path)
        return video_path, False

def encode_video_to_base64(video_path):
    """
    å°†è§†é¢‘æ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼
    """
    try:
        with open(video_path, "rb") as f:
            video_bytes = f.read()
            video_base64 = base64.b64encode(video_bytes).decode('utf-8')
        return video_base64
    except FileNotFoundError:
        print(f"âŒ Video file not found: {video_path}")
        return None

def call_vlm_model(video_path, question, model_name="qwen3-vl-plus"):
    """
    è°ƒç”¨VLMæ¨¡å‹æ¥ç†è§£è§†é¢‘å†…å®¹å¹¶å›ç­”é—®é¢˜
    """
    SUPPORT_JSON_MODELS = ["Qwen/Qwen3-VL-30B-A3B-Instruct", "Qwen/Qwen3-Omni-30B-A3B-Instruct", "qwen3-vl-plus", "qwen3-vl-flash", "qwen-vl-max-latest"]
    api_provider = MODEL_TO_API.get(model_name, "siliconflow")
    api_config = API_CONFIGS[api_provider]
    
    client = OpenAI(api_key=api_config["api_key"], base_url=api_config["base_url"])
    
    system_prompt = """
    You are an expert video understanding AI. 
    Analyze the video and answer the following question in detail.
    Include reasoning about what you see in the video.
    """

    user_prompt = question

    # å‹ç¼©è§†é¢‘
    compressed_video_path, is_temp_file = compress_video_smart(video_path)
    
    try:
        # ç¼–ç è§†é¢‘ä¸ºbase64
        video_base64 = encode_video_to_base64(compressed_video_path)
        if video_base64 is None:
            return {"error": "Failed to encode video"}

        # æ„å»ºè§†é¢‘å†…å®¹éƒ¨åˆ†
        video_url = f"data:video/mp4;base64,{video_base64}"
        
        if api_provider == "aliyun":
            # é˜¿é‡Œäº‘ OpenAI å…¼å®¹æ¨¡å¼æ ¼å¼ (type: video_url)
            video_content = {
                "type": "video_url",
                "video_url": {"url": video_url}
            }
        else:
            # SiliconFlow æ ¼å¼ (å¸¦ fps ç­‰å‚æ•°)
            video_content = {
                "type": "video_url",
                "video_url": {
                    "url": video_url,
                    "detail": "auto",
                    "max_frames": 12,
                    "fps": 1
                }
            }

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": [{"type": "text", "text": user_prompt}, video_content]}
        ]

        max_retries = 3
        retry_delay = 5
        
        for retry in range(max_retries):
            try:
                print(f"ğŸ“ Calling {model_name} ({api_provider})...")
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=0.1,
                    max_tokens=1024,
                    response_format={"type": "json_object"} if model_name in SUPPORT_JSON_MODELS else None,
                    timeout=120
                )
                
                content = response.choices[0].message.content.strip()
                # ç§»é™¤å¯èƒ½çš„JSONæ ‡è®°
                content = content.replace("```json", "").replace("```", "").strip()
                
                try:
                    # å°è¯•è§£æä¸ºJSON
                    return json.loads(content)
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONï¼Œè¿”å›çº¯æ–‡æœ¬
                    return {"answer": content, "reasoning": "No structured reasoning available"}
                    
            except Exception as e:
                print(f"âŒ {model_name} Request Failed: {e}")
                if retry < max_retries - 1:
                    print(f"ğŸ”„ Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                else:
                    return {"error": f"Max retries exceeded: {e}"}
                    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if is_temp_file and os.path.exists(compressed_video_path):
            try:
                os.remove(compressed_video_path)
                print(f"ğŸ—‘ï¸ Cleaned up temporary file: {compressed_video_path}")
            except OSError:
                pass

# ================= ä¸»ç¨‹åº =================

def main():
    """
    ä¸»ç¨‹åºï¼šæµ‹è¯•VLMæ¨¡å‹å¯¹è§†é¢‘çš„ç†è§£
    """
    print("ğŸ¬ è§†é¢‘ç†è§£æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥é»˜è®¤è§†é¢‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DEFAULT_VIDEO_PATH):
        print(f"âŒ é»˜è®¤è§†é¢‘ä¸å­˜åœ¨: {DEFAULT_VIDEO_PATH}")
        print("è¯·ç¡®ä¿è§†é¢‘æ–‡ä»¶åœ¨æŒ‡å®šè·¯å¾„ä¸‹ã€‚")
        return
    
    print(f"ğŸ“¹ ä½¿ç”¨è§†é¢‘: {DEFAULT_VIDEO_PATH}")
    print(f"â“ é»˜è®¤é—®é¢˜: {DEFAULT_QUESTION}")
    print("=" * 50)
    
    # è·å–ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
    user_question = input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤é—®é¢˜ï¼‰: ").strip()
    if not user_question:
        user_question = DEFAULT_QUESTION
    
    print(f"\nğŸ’¬ é—®é¢˜: {user_question}")
    
    # é€‰æ‹©æ¨¡å‹
    print("\nğŸ¤– å¯ç”¨æ¨¡å‹:")
    for i, model in enumerate(TEST_MODELS, 1):
        provider = MODEL_TO_API.get(model, "siliconflow")
        print(f"   {i}. {model} ({provider})")
    
    try:
        model_choice = input("è¯·é€‰æ‹©æ¨¡å‹ç¼–å·ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰: ").strip()
        if model_choice:
            model_index = int(model_choice) - 1
            if 0 <= model_index < len(TEST_MODELS):
                selected_model = TEST_MODELS[model_index]
            else:
                print("âš ï¸ æ— æ•ˆçš„é€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                selected_model = "qwen3-vl-plus"
        else:
            selected_model = "qwen3-vl-plus"
    except ValueError:
        print("âš ï¸ æ— æ•ˆçš„è¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
        selected_model = "qwen3-vl-plus"
    
    print(f"\nâœ… é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
    
    # è°ƒç”¨æ¨¡å‹
    print("\n" + "=" * 50)
    print("ğŸ”„ æ­£åœ¨åˆ†æè§†é¢‘...")
    start_time = time.time()
    
    result = call_vlm_model(DEFAULT_VIDEO_PATH, user_question, selected_model)
    
    end_time = time.time()
    print(f"â±ï¸ åˆ†æå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
    print("=" * 50)
    
    # æ˜¾ç¤ºç»“æœ
    print("\nğŸ“Š åˆ†æç»“æœ:")
    print("=" * 50)
    
    if "error" in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
    else:
        # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„ç»“æœå­—æ®µ
        if "answer" in result:
            print(f"ğŸ’¡ å›ç­”: {result['answer']}")
        if "reasoning" in result:
            print(f"ğŸ¤” æ¨ç†: {result['reasoning']}")
        # å¤„ç†ä¸åŒæ¨¡å‹è¿”å›çš„ä¸åŒæ ¼å¼
        if "content" in result:
            print(f"ğŸ’¡ å›ç­”: {result['content']}")
        if "analysis" in result:
            print(f"ğŸ¤” åˆ†æ: {result['analysis']}")
        if "result" in result:
            print(f"ğŸ“‹ ç»“æœ: {result['result']}")
        if "explanation" in result:
            print(f"ğŸ“ è§£é‡Š: {result['explanation']}")
        
        # å¦‚æœæ²¡æœ‰ä»¥ä¸Šå­—æ®µï¼Œæ‰“å°åŸå§‹ç»“æœ
        if not any(key in result for key in ["answer", "reasoning", "content", "analysis", "result", "explanation"]):
            print("ğŸ“‹ åŸå§‹ç»“æœ:")
            print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("\n" + "=" * 50)
    print("âœ… æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()