import os
import json
import base64
import re
import time
import subprocess
from tqdm import tqdm
from openai import OpenAI
from prettytable import PrettyTable
from concurrent.futures import ThreadPoolExecutor, as_completed

# ================= é…ç½®éƒ¨åˆ† =================

# APIé…ç½®ï¼ŒæŒ‰æ¨¡å‹æä¾›å•†åˆ†ç±»
API_CONFIGS = {
    "aliyun": {
        "api_key": "sk-7e6b3a62b1f64945a5a4a9347afa5c72",
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
    },
    "siliconflow": {
        "api_key": "sk-izrxbwrnxotwsvcngnnmwivxmyqukrivnjcoszzpscmfasjz",
        "base_url": "https://api.siliconflow.cn/v1"  # ä¿®æ­£ï¼šå»æ‰äº†æœ«å°¾çš„ /chat/completions
    }
}

# é…ç½®è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
TEST_MODELS = [
    # é˜¿é‡Œäº‘æ¨¡å‹
    "qwen-vl-max-latest",
    "qwen3-vl-30b-a3b-thinking",
    "qwen3-vl-plus",
    "qwen3-vl-flash",
    # SiliconFlowæ¨¡å‹
    "Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "zai-org/GLM-4.6V"
]

# æ¨¡å‹åˆ°APIæä¾›å•†çš„æ˜ å°„
MODEL_TO_API = {
    "qwen3-vl-plus": "aliyun",
    "qwen3-vl-flash": "aliyun",
    "qwen-vl-max-latest": "aliyun",
    "qwen3-vl-30b-a3b-thinking": "aliyun",
    "Qwen/Qwen3-Omni-30B-A3B-Instruct": "siliconflow",
    "zai-org/GLM-4.6V": "siliconflow",
    "Qwen/Qwen3-VL-30B-A3B-Instruct": "siliconflow"
}

VIDEO_DIR = "t2v_videos"

# æœ€å¤§å¹¶å‘æ•°è®¾ç½®ï¼ˆæ ¹æ®APIé™åˆ¶å’Œç³»ç»Ÿèµ„æºè°ƒæ•´ï¼‰
# è®¾ç½®ä¸ºæ¨¡å‹æ€»æ•°+1ï¼Œç¡®ä¿æ¯ä¸ªè§†é¢‘èƒ½å¹¶å‘è°ƒç”¨æ‰€æœ‰æ¨¡å‹
MAX_CONCURRENT_MODELS = len(TEST_MODELS) + 1

# ================= è¾…åŠ©å‡½æ•° =================

def sanitize_filename(name):
    name = re.sub(r'[\\/*?:"<>|]', "", name)
    return name.replace(" ", "_")

def extract_video_frame(video_path, time_second=5):
    """
    æå–è§†é¢‘æŒ‡å®šæ—¶é—´ç‚¹çš„å¸§
    å‚æ•°:
    - video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    - time_second: è¦æå–çš„æ—¶é—´ç‚¹ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸º5ç§’
    
    è¿”å›:
    - (å¸§å›¾åƒè·¯å¾„, æ˜¯å¦æ˜¯ä¸´æ—¶æ–‡ä»¶)
    """
    if not os.path.exists(video_path):
        return None, False
    
    temp_frame_path = video_path.replace(".mp4", f"_frame_{time_second}s.jpg")
    
    cmd = [
        "ffmpeg", "-y",                # è¦†ç›–è¾“å‡º
        "-i", video_path,              # è¾“å…¥è§†é¢‘
        "-ss", str(time_second),       # å¼€å§‹æ—¶é—´ç‚¹
        "-vframes", "1",              # åªæå–ä¸€å¸§
        "-q:v", "2",                  # é«˜è´¨é‡
        temp_frame_path
    ]
    
    try:
        # æ‰§è¡Œæå–ï¼Œé™é»˜è¾“å‡º
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        
        if os.path.exists(temp_frame_path):
            print(f"ğŸ–¼ï¸  Extracted frame at {time_second}s from {os.path.basename(video_path)}")
            return temp_frame_path, True
        else:
            return None, False
            
    except Exception as e:
        print(f"âŒ Frame extraction failed: {e}")
        if os.path.exists(temp_frame_path):
            os.remove(temp_frame_path)
        return None, False

def compress_video_smart(video_path, target_size_mb=7.0):
    """
    æ™ºèƒ½å‹ç¼©è§†é¢‘ï¼šä»…é€šè¿‡é™ä½å¸§ç‡æ¥å‹ç¼©è§†é¢‘ï¼Œå§‹ç»ˆä¿æŒé«˜ç”»è´¨ï¼ˆCRF 18ï¼‰ä¸å˜ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. æ ¹æ®è§†é¢‘æ–‡ä»¶å¤§å°è‡ªé€‚åº”é€‰æ‹©åˆé€‚çš„å¸§ç‡è¿›è¡Œå‹ç¼©
    2. æ— è®ºå‹ç¼©ç¨‹åº¦å¦‚ä½•ï¼Œå§‹ç»ˆä¿æŒé«˜ç”»è´¨å‚æ•°ï¼ˆCRF 18ï¼‰
    3. ç§»é™¤éŸ³é¢‘ä»¥è¿›ä¸€æ­¥å‡å°æ–‡ä»¶å¤§å°
    
    å‚æ•°è¯´æ˜ï¼š
    - video_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
    - target_size_mb: ç›®æ ‡æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ä¸º7.0MB
    
    å‹ç¼©ç­–ç•¥ï¼š
    1. æ ¹æ®æ–‡ä»¶å¤§å°è‡ªåŠ¨é€‰æ‹©å¸§ç‡ï¼š
       - å°äºç­‰äº15MBï¼šä½¿ç”¨5fpsï¼ˆé€‚ä¸­å¸§ç‡ï¼Œä¿æŒè‰¯å¥½æµç•…åº¦ï¼‰
       - 15-30MBï¼šä½¿ç”¨4fpsï¼ˆè¾ƒä½å¸§ç‡ï¼Œä½†ä»ä¿æŒå…³é”®åŠ¨ä½œå¯è§ï¼‰
       - å¤§äº30MBï¼šä½¿ç”¨3fpsï¼ˆä½å¸§ç‡ï¼Œä½†èƒ½ä¿ç•™é‡è¦è§†è§‰ä¿¡æ¯ï¼‰
    2. å¦‚æœå‹ç¼©åä»è¶…è¿‡ç›®æ ‡å¤§å°ï¼Œä¼šè¿›ä¸€æ­¥é™ä½å¸§ç‡è‡³2fpsæˆ–1fps
    3. å§‹ç»ˆä½¿ç”¨ç›¸åŒçš„é«˜ç”»è´¨ç¼–ç å‚æ•°ï¼ˆCRF 18ï¼‰ç¡®ä¿è§†é¢‘è´¨é‡
    
    å…³é”®è°ƒæ•´ï¼š
    - target_size_mb é»˜è®¤å€¼è®¾ç½®ä¸º 7.0MBï¼Œå› ä¸º Base64 ç¼–ç ä¼šä½¿æ–‡ä»¶å¤§å°å¢åŠ çº¦ 33%
      - 7.0MB * 1.33 â‰ˆ 9.3MB (å®‰å…¨ï¼Œå°äº API çš„ 10MB é™åˆ¶)
      - 9.0MB * 1.33 â‰ˆ 12.0MB (ä¼šæŠ¥é”™ Exceeded limit)
    - ä¸å†é€šè¿‡å¢åŠ CRFå€¼æ¥é™ä½ç”»è´¨ï¼Œåªä¾èµ–å¸§ç‡è°ƒæ•´æ¥æ§åˆ¶æ–‡ä»¶å¤§å°
    
    è¿”å›: (å¤„ç†åçš„æ–‡ä»¶è·¯å¾„, æ˜¯å¦æ˜¯ä¸´æ—¶æ–‡ä»¶)
    """

    if not os.path.exists(video_path):
        return video_path, False

    file_size = os.path.getsize(video_path) / (1024 * 1024)
    
    # ä¸ç®¡æ–‡ä»¶å¤§å°ï¼Œéƒ½è¿›è¡Œå‹ç¼©
    print(f"ğŸ“¦ Video {os.path.basename(video_path)} is {file_size:.2f}MB. Compressing to optimize for API...")
    
    temp_path = video_path.replace(".mp4", "_compressed_temp.mp4")
    
    # ç­–ç•¥ï¼šé™ä½å¸§ç‡ï¼Œä½†ä¿æŒé«˜è´¨é‡ï¼ˆå›ºå®šCRF 18ï¼‰
    # æ ¹æ®æ–‡ä»¶å¤§å°é€‰æ‹©åˆé€‚çš„å¸§ç‡
    if file_size > 30:
        target_fps = "3"  # éå¸¸å¤§çš„æ–‡ä»¶ä½¿ç”¨æ›´ä½çš„å¸§ç‡
    elif file_size > 15:
        target_fps = "4"  # è¾ƒå¤§çš„æ–‡ä»¶ä½¿ç”¨è¾ƒä½çš„å¸§ç‡
    else:
        target_fps = "5"  # æ­£å¸¸å¤§å°çš„æ–‡ä»¶ä½¿ç”¨é€‚ä¸­çš„å¸§ç‡

    cmd = [
        "ffmpeg", "-y",                # è¦†ç›–è¾“å‡º
        "-i", video_path,              # è¾“å…¥
        "-r", target_fps,              # ç›®æ ‡å¸§ç‡
        "-c:v", "libx264",             # ç¼–ç å™¨
        "-pix_fmt", "yuv420p",         # å¼ºåˆ¶ä½¿ç”¨ yuv420p åƒç´ æ ¼å¼
        "-crf", "18",                  # æ’å®šè´¨é‡å› å­ (18=é«˜ç”»è´¨/è§†è§‰æ— æŸ)
        "-preset", "veryfast",         # ç¼–ç é€Ÿåº¦
        "-an",                         # ç§»é™¤éŸ³é¢‘
        temp_path
    ]
    
    try:
        # æ‰§è¡Œå‹ç¼©ï¼Œé™é»˜è¾“å‡º
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        
        # æ£€æŸ¥å‹ç¼©åçš„å¤§å°
        new_size = os.path.getsize(temp_path) / (1024 * 1024)
        
        # å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œåªé€šè¿‡è¿›ä¸€æ­¥é™ä½å¸§ç‡æ¥å‹ç¼©ï¼Œä¸æ”¹å˜ç”»è´¨å‚æ•°
        if new_size > target_size_mb:
            print(f"âš ï¸ Still too large ({new_size:.2f}MB). Further compressing by reducing frame rate only...")
            
            # æ›´æ¿€è¿›åœ°é™ä½å¸§ç‡ï¼Œä½†ä¿æŒç›¸åŒçš„ç”»è´¨å‚æ•°
            lower_fps = "2" if target_fps != "2" else "1"
            
            cmd_reduce_fps = [
                "ffmpeg", "-y", "-i", video_path,
                "-r", lower_fps, "-c:v", "libx264",
                "-pix_fmt", "yuv420p",
                "-crf", "18", "-preset", "veryfast", "-an",
                temp_path
            ]
            subprocess.run(cmd_reduce_fps, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
            new_size = os.path.getsize(temp_path) / (1024 * 1024)

        print(f"âœ… Compressed to {new_size:.2f}MB (FPS: {target_fps}, Quality: High - CRF 18)")
        return temp_path, True
        
    except Exception as e:
        print(f"âŒ Compression failed (ffmpeg might be missing): {e}. Using original.")
        if os.path.exists(temp_path):
            os.remove(temp_path)
        return video_path, False

def call_transit_model(raw_text):
    """è°ƒç”¨ä¸­è½¬æ¨¡å‹è½¬æ¢æ ¼å¼"""
    transit_system_prompt = """
    You are a professional text format converter. Your job is to convert the given text into a strict JSON format.
    The JSON should have two fields:
    1. "answer": The selected option letter (e.g., "A", "B", "C", "D")
    2. "reasoning": "<Short explanation>"
    OUTPUT FORMAT: Return a STRICT JSON object with no additional text.
    """
    
    transit_user_prompt = f"Please convert the following text into JSON format:\n{raw_text}"
    
    transit_messages = [
        {"role": "system", "content": transit_system_prompt},
        {"role": "user", "content": transit_user_prompt}
    ]
    
    api_config = API_CONFIGS["siliconflow"]
    transit_client = OpenAI(api_key=api_config["api_key"], base_url=api_config["base_url"])
    
    for retry in range(3):
        try:
            response = transit_client.chat.completions.create(
                model="Qwen/Qwen3-Next-80B-A3B-Instruct",
                messages=transit_messages,
                temperature=0.1,
                max_tokens=512,
                response_format={"type": "json_object"},
                timeout=60
            )
            content = response.choices[0].message.content
            content = content.replace("```json", "").replace("```", "").strip()
            return json.loads(content)
        except Exception as e:
            if retry == 2: return {"answer": "N/A", "reasoning": f"Transit Error: {e}"}
            time.sleep(2)
    return {"answer": "N/A", "reasoning": "Transit failed"}

def call_vlm_model(media_path, question, options=None, model_name=None, is_video=True):
    """è°ƒç”¨ VLM æ¨¡å‹
    
    å‚æ•°:
    - media_path: è§†é¢‘æˆ–å›¾åƒæ–‡ä»¶è·¯å¾„
    - question: é—®é¢˜æ–‡æœ¬
    - options: é€‰é¡¹å­—å…¸ï¼ˆä»…ç”¨äºé€‰æ‹©é¢˜ï¼‰
    - model_name: æ¨¡å‹åç§°
    - is_video: æ˜¯å¦ä¸ºè§†é¢‘ï¼ˆTrueï¼‰æˆ–å›¾åƒï¼ˆFalseï¼‰
    
    è¿”å›:
    - æ¨¡å‹å“åº”ç»“æœ
    """
    SUPPORT_JSON_MODELS = ["Qwen/Qwen3-VL-30B-A3B-Instruct", "Qwen/Qwen3-Omni-30B-A3B-Instruct", "qwen3-vl-plus", "qwen3-vl-flash", "qwen-vl-max-latest"]
    api_provider = MODEL_TO_API.get(model_name, "siliconflow") if model_name else "siliconflow"
    api_config = API_CONFIGS[api_provider]
    
    client = OpenAI(api_key=api_config["api_key"], base_url=api_config["base_url"])
    
    # æ ¹æ®æ˜¯å¦æ˜¯é€‰æ‹©é¢˜è®¾ç½®ä¸åŒçš„ç³»ç»Ÿæç¤º
    if options:
        system_prompt = """
        You are an expert video understanding AI. 
        Analyze the media and return a JSON object: {"answer": "<option>", "reasoning": "<text>"}
        """
    else:
        system_prompt = """
        You are an expert video understanding AI. 
        Analyze the image and describe what you see in detail.
        """

    # æ„é€ ç”¨æˆ·æç¤º
    if options:
        user_prompt = f"""
        # MEDIA QUESTION:
        **Question:** {question}
        **OPTIONS:**
        {chr(10).join([f"{key}. {value}" for key, value in options.items()])}
        Select the correct answer.
        """
    else:
        user_prompt = question

    try:
        with open(media_path, "rb") as f:
            media_bytes = f.read()
            
        if is_video:
            # è§†é¢‘å¤„ç†
            media_base64 = base64.b64encode(media_bytes).decode('utf-8')
            media_url = f"data:video/mp4;base64,{media_base64}"
            
            if api_provider == "aliyun":
                # é˜¿é‡Œäº‘ OpenAI å…¼å®¹æ¨¡å¼æ ¼å¼ (type: video_url)
                media_content = {
                    "type": "video_url",
                    "video_url": {"url": media_url}
                }
            else:
                # SiliconFlow æ ¼å¼ (å¸¦ fps ç­‰å‚æ•°)
                media_content = {
                    "type": "video_url",
                    "video_url": {
                        "url": media_url,
                        "detail": "auto",
                        "max_frames": 12,
                        "fps": 1
                    }
                }
        else:
            # å›¾åƒå¤„ç†
            media_base64 = base64.b64encode(media_bytes).decode('utf-8')
            media_url = f"data:image/jpeg;base64,{media_base64}"
            
            media_content = {
                "type": "image_url",
                "image_url": {"url": media_url}
            }

    except FileNotFoundError:
        return {"answer": "N/A", "reasoning": "Media file not found during read"}
    except Exception as e:
        return {"answer": "N/A", "reasoning": f"Media processing error: {e}"}

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": [{"type": "text", "text": user_prompt}, media_content]}
    ]

    max_retries = 3
    retry_delay = 5
    
    for retry in range(max_retries):
        try:
            # åªæœ‰åœ¨å¤„ç†é€‰æ‹©é¢˜æ—¶æ‰è¦æ±‚JSONæ ¼å¼å“åº”
            use_json_format = model_name in SUPPORT_JSON_MODELS and options is not None
            
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.1,
                max_tokens=512,
                response_format={"type": "json_object"} if use_json_format else None,
                timeout=60
            )
            
            content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
            
            if use_json_format:
                # é€‰æ‹©é¢˜ï¼šè§£æJSONå“åº”
                return json.loads(content)
            elif options is not None:
                # é€‰æ‹©é¢˜ä½†ä¸æ”¯æŒç›´æ¥JSONï¼šä½¿ç”¨ä¸­è½¬æ¨¡å‹
                return call_transit_model(content)
            else:
                # éé€‰æ‹©é¢˜ï¼ˆæè¿°ä»»åŠ¡ï¼‰ï¼šç›´æ¥è¿”å›åŒ…å«reasoningçš„å­—å…¸
                return {"reasoning": content, "answer": "N/A"}
                
        except Exception as e:
            print(f"âŒ {model_name} Request Failed: {e}")
            if retry < max_retries - 1:
                time.sleep(retry_delay)
                retry_delay *= 2
            else:
                return {"answer": "N/A", "reasoning": f"Exception: {e}"}
    
    return {"answer": "N/A", "reasoning": "Max retries exceeded"}



# ================= ä¸»ç¨‹åº =================

def process_video(eval_entry, prompt_index, test_results, lock, processed_videos):
    """å¤„ç†å•ä¸ªè§†é¢‘çš„å‡½æ•°ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œ"""
    object_name = eval_entry['object_name']
    scenario_type = eval_entry['scenario_type']
    
    key = f"{object_name}_{scenario_type}"
    if key not in prompt_index:
        return
    
    if eval_entry['status'] != 'evaluated' or not eval_entry.get('best_video'):
        return
    
    prompt_entry = prompt_index[key]
    mcq = prompt_entry['mcq']
    
    best_video_file = eval_entry['best_video']
    original_video_path = os.path.join(VIDEO_DIR, best_video_file)
    
    # ä½¿ç”¨object_name_scenario_typeç»„åˆä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œé¿å…åŒä¸€è§†é¢‘è¢«é‡å¤å¤„ç†
    unique_key = f"{object_name}_{scenario_type}"
    
    # æ£€æŸ¥è¯¥ç»„åˆæ˜¯å¦å·²ç»å¤„ç†è¿‡ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
    if unique_key in processed_videos:
        print(f"â­ï¸  Skipping {best_video_file} ({object_name} - {scenario_type})... already processed")
        return
    
    # æå‰å°†è§†é¢‘æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œé¿å…åç»­å¯èƒ½çš„é‡å¤å¤„ç†
    with lock:
        processed_videos.add(unique_key)
    
    print(f"ğŸ”„ Processing {best_video_file} ({object_name} - {scenario_type})...")
    
    # === è§†é¢‘å¤„ç† ===
    current_video_path, is_temp_video = compress_video_smart(original_video_path)
    
    # æå–ç¬¬5ç§’çš„å¸§å›¾åƒ
    frame_path, is_temp_frame = extract_video_frame(current_video_path, time_second=5)
    
    if not frame_path:
        print(f"âš ï¸  Failed to extract frame from {best_video_file}. Skipping...")
        # æ¸…ç†ä¸´æ—¶è§†é¢‘æ–‡ä»¶
        if is_temp_video and os.path.exists(current_video_path):
            try:
                os.remove(current_video_path)
            except OSError:
                pass
        return
    
    # ç›´æ¥ä½¿ç”¨JSONä¸­çš„åŸå§‹é¢˜å¹²
    original_question = mcq['question']
    
    try:
        # å¹¶è¡Œè°ƒç”¨æ‰€æœ‰æ¨¡å‹
        with ThreadPoolExecutor(max_workers=min(MAX_CONCURRENT_MODELS, len(TEST_MODELS))) as executor:
            # æäº¤æ‰€æœ‰æ¨¡å‹è°ƒç”¨ä»»åŠ¡
            future_to_model = {
                executor.submit(process_two_stage_question, current_video_path, frame_path, original_question, mcq['options'], model_name): model_name
                for model_name in TEST_MODELS
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_model):
                model_name = future_to_model[future]
                try:
                    first_stage_response, second_stage_response = future.result()
                    
                    correct_answer = mcq['correct_answer']
                    model_answer = second_stage_response.get('answer', 'N/A')
                    is_correct = str(model_answer).upper() == str(correct_answer).upper()
                    
                    # ä½¿ç”¨é”ç¡®ä¿çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœåˆ—è¡¨
                    with lock:
                        test_results.append({
                            "object_name": object_name,
                            "scenario_type": scenario_type,
                            "video_file": best_video_file,
                            "mcq_question": original_question,
                            "mcq_options": mcq['options'],
                            "correct_answer": correct_answer,
                            "model_name": model_name,
                            "model_answer": model_answer,
                            "is_correct": is_correct,
                            "first_stage_description": first_stage_response.get('reasoning', ''),
                            "second_stage_reasoning": second_stage_response.get('reasoning', ''),
                            "original_score": eval_entry['best_score']
                        })
                        
                    print(f"   [{model_name}] Ans: {model_answer} ({'âœ…' if is_correct else 'âŒ'})")
                except Exception as e:
                    print(f"   [{model_name}] Error: {e}")
                    # ä½¿ç”¨é”ç¡®ä¿çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœåˆ—è¡¨
                    with lock:
                        test_results.append({
                            "object_name": object_name,
                            "scenario_type": scenario_type,
                            "video_file": best_video_file,
                            "mcq_question": original_question,
                            "mcq_options": mcq['options'],
                            "correct_answer": mcq['correct_answer'],
                            "model_name": model_name,
                            "model_answer": "N/A",
                            "is_correct": False,
                            "first_stage_description": "",
                            "second_stage_reasoning": f"Error: {e}",
                            "original_score": eval_entry['best_score']
                        })
    
    finally:
        # === æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ===
        if is_temp_video and os.path.exists(current_video_path):
            try:
                os.remove(current_video_path)
            except OSError:
                pass
        
        if is_temp_frame and os.path.exists(frame_path):
            try:
                os.remove(frame_path)
            except OSError:
                pass


def process_two_stage_question(video_path, frame_path, original_question, options, model_name):
    """
    ä¸¤é˜¶æ®µæé—®å¤„ç†å‡½æ•°
    1. ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨ç¬¬5ç§’å¸§å›¾åƒæè¿°è§†é¢‘
    2. ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨è§†é¢‘å’Œç¬¬ä¸€é˜¶æ®µçš„æè¿°å›ç­”åŸå§‹é—®é¢˜
    """
    # ç¬¬ä¸€é˜¶æ®µï¼šä¸Šä¼ å¸§å›¾åƒå¹¶é—®"Describe the video"
    first_stage_question = "Describe what you see in this frame. Provide a detailed description of the scene."
    first_stage_response = call_vlm_model(frame_path, first_stage_question, None, model_name, is_video=False)
    
    # ç¬¬äºŒé˜¶æ®µï¼šä¸Šä¼ è§†é¢‘ï¼Œå¹¶é™„å¸¦ç¬¬ä¸€é˜¶æ®µçš„å›ç­”
    second_stage_question = f"{original_question}\n\nFirst, here's a description of the video frame at 5 seconds: {first_stage_response.get('reasoning', '')}"
    second_stage_response = call_vlm_model(video_path, second_stage_question, options, model_name, is_video=True)
    
    return first_stage_response, second_stage_response

def main():
    import threading
    
    print(f"ğŸš€ Starting Video Understanding Test using {', '.join(TEST_MODELS)}...")
    
    eval_files = [f for f in os.listdir('.') if f.startswith('physibench_evaluated_v') and f.endswith('.json')]
    eval_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    if not eval_files:
        print("âŒ No evaluation files found.")
        return
    
    eval_file = eval_files[0]
    version = re.search(r'v(\d+)', eval_file).group(1)
    
    # å¯»æ‰¾å¯¹åº”çš„MCQç»“æœæ–‡ä»¶ï¼Œæ”¯æŒä¸åŒçš„å‘½åæ ¼å¼ï¼ˆå¦‚mcq_blind_test_results_v76_unique.jsonï¼‰
    mcq_files = [f for f in os.listdir('.') if f.startswith('mcq_blind_test_results_') and f.endswith('.json')]
    matched_mcq_files = []
    for f in mcq_files:
        match = re.search(r'v(\d+)', f)
        if match and match.group(1) == version:
            matched_mcq_files.append(f)
    
    if not matched_mcq_files:
        print(f"âŒ No MCQ result files found for version v{version}")
        return
    
    # é€‰æ‹©æœ€æ–°çš„MCQç»“æœæ–‡ä»¶
    mcq_file = max(matched_mcq_files, key=os.path.getmtime)
    
    with open(eval_file, "r", encoding='utf-8') as f: eval_results = json.load(f)
    with open(mcq_file, "r", encoding='utf-8') as f: mcq_results = json.load(f)
    
    # åˆ›å»ºç´¢å¼•ï¼Œæ˜ å°„object_name_scenario_typeåˆ°mcqç»“æœ
    prompt_index = {f"{result['director_data']['object_name']}_{result['director_data']['scenario_type']}": result for result in mcq_results if result.get('blind_test_passed', False)}
    
    test_results = []
    lock = threading.Lock()  # ç”¨äºçº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœåˆ—è¡¨
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²å­˜åœ¨çš„æµ‹è¯•ç»“æœæ–‡ä»¶ï¼Œç”¨äºæ–­ç‚¹ç»­ä¼ 
    output_file = f"video_test_ours_v{version}.json"
    processed_videos = set()
    
    if os.path.exists(output_file):
        try:
            with open(output_file, "r", encoding='utf-8') as f:
                existing_results = json.load(f)
            test_results = existing_results
            
            # æå–å·²å¤„ç†çš„object_name_scenario_typeç»„åˆ
            for result in existing_results:
                unique_key = f"{result['object_name']}_{result['scenario_type']}"
                processed_videos.add(unique_key)
            
            print(f"ğŸ“‹ Found existing results file: {output_file}")
            print(f"   - {len(existing_results)} results loaded")
            print(f"   - {len(processed_videos)} unique object-scenario combinations already processed")
        except (json.JSONDecodeError, KeyError) as e:
            print(f"âš ï¸  Failed to load existing results: {e}")
            print("   Starting fresh...")
    
    # è®¡ç®—æ€»çš„å¹¶å‘æ•°
    # æ¯ä¸ªè§†é¢‘éœ€è¦å¤„ç†len(TEST_MODELS)ä¸ªæ¨¡å‹ï¼Œæ‰€ä»¥æ€»çš„å¹¶å‘æ•°åº”è¯¥æ˜¯MAX_CONCURRENT_MODELS * è§†é¢‘å¹¶å‘æ•°
    # é™ä½å¹¶å‘æ•°ä»¥é¿å…APIé€Ÿç‡é™åˆ¶ (TPM limit reached)
    video_concurrency = 2
    total_concurrent_workers = video_concurrency
    
    print(f"âš™ï¸  Using {total_concurrent_workers} concurrent video workers, each with up to {MAX_CONCURRENT_MODELS} model workers...")
    
    # å¹¶è¡Œå¤„ç†æ‰€æœ‰è§†é¢‘
    with ThreadPoolExecutor(max_workers=total_concurrent_workers) as executor:
        # æäº¤æ‰€æœ‰è§†é¢‘å¤„ç†ä»»åŠ¡
        futures = []
        valid_entries = 0
        for eval_entry in eval_results:
            object_name = eval_entry['object_name']
            scenario_type = eval_entry['scenario_type']
            key = f"{object_name}_{scenario_type}"
            
            # åªæäº¤æœ‰æ•ˆçš„è¯„ä¼°æ¡ç›®
            if key in prompt_index and eval_entry['status'] == 'evaluated' and eval_entry.get('best_video'):
                future = executor.submit(process_video, eval_entry, prompt_index, test_results, lock, processed_videos)
                futures.append(future)
                valid_entries += 1
        
        print(f"ğŸ“‹ Found {valid_entries} valid evaluation entries matching MCQ blind test results...")
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        print(f"ğŸ“‹ Submitted {len(futures)} video processing tasks...")
        for future in tqdm(as_completed(futures), total=len(futures), desc="Processing Videos"):
            try:
                future.result()
            except Exception as e:
                print(f"âŒ Video processing error: {e}")

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if test_results:
        correct_count = sum(1 for r in test_results if r['is_correct'])
        print(f"\nğŸ“Š Overall Accuracy: {correct_count / len(test_results) * 100:.1f}%")
        
    # ä¿å­˜
    with open(output_file, "w", encoding='utf-8') as f:
        json.dump(test_results, f, indent=2, ensure_ascii=False)
    print(f"\nâœ… Results saved to {output_file}")
    
    # ç»Ÿè®¡æ¯ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªåœºæ™¯ä¸‹çš„æ­£ç¡®ç‡
    if not test_results:
        print("\nâŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯ç»Ÿè®¡")
        return
    
    print(f"\nğŸ“Š å¼€å§‹ç»Ÿè®¡æ¯ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªåœºæ™¯ä¸‹çš„æ­£ç¡®ç‡...")
    
    # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„åœºæ™¯ç±»å‹å’Œæ¨¡å‹åç§°
    scenario_types = sorted(set(r['scenario_type'] for r in test_results))
    model_names = sorted(set(r['model_name'] for r in test_results))
    
    # ç»Ÿè®¡æ•°æ®ç»“æ„: {model: {scenario: (correct_count, total_count)}}
    stats = {}
    for model in model_names:
        stats[model] = {}
        for scenario in scenario_types:
            # ç­›é€‰è¯¥æ¨¡å‹åœ¨è¯¥åœºæ™¯ä¸‹çš„æ‰€æœ‰ç»“æœ
            model_scenario_results = [
                r for r in test_results 
                if r['model_name'] == model and r['scenario_type'] == scenario
            ]
            if not model_scenario_results:
                stats[model][scenario] = (0, 0)
                continue
            
            total = len(model_scenario_results)
            correct = sum(1 for r in model_scenario_results if r['is_correct'])
            stats[model][scenario] = (correct, total)
    
    # ä½¿ç”¨ PrettyTable æ‰“å°ç»Ÿè®¡è¡¨æ ¼
    print(f"\n{'='*100}")
    print("ğŸ“ˆ å„æ¨¡å‹åœ¨å„åœºæ™¯ä¸‹çš„æ­£ç¡®ç‡ç»Ÿè®¡")
    print(f"{'='*100}")
    
    # åˆ›å»ºè¡¨æ ¼
    table = PrettyTable()
    
    # è®¾ç½®è¡¨å¤´
    field_names = ["åœºæ™¯ç±»å‹"]
    for model in model_names:
        field_names.append(model)
    field_names.append("æƒ…æ™¯æ€»è®¡")  # æ·»åŠ æƒ…æ™¯æ€»è®¡åˆ—
    table.field_names = field_names
    
    # å¡«å……è¡¨æ ¼å†…å®¹
    for scenario in scenario_types:
        row = [scenario]
        scenario_total_correct = 0
        scenario_total_count = 0
        
        for model in model_names:
            correct, total = stats[model][scenario]
            if total == 0:
                accuracy = "N/A"
            else:
                accuracy = f"{correct/total*100:.1f}% ({correct}/{total})"
            row.append(accuracy)
            
            # ç´¯è®¡åœºæ™¯çš„æ€»æ­£ç¡®æ•°å’Œæ€»æµ‹è¯•æ•°
            scenario_total_correct += correct
            scenario_total_count += total
        
        # è®¡ç®—åœºæ™¯æ€»è®¡
        if scenario_total_count == 0:
            scenario_accuracy = "N/A"
        else:
            scenario_accuracy = f"{scenario_total_correct/scenario_total_count*100:.1f}% ({scenario_total_correct}/{scenario_total_count})"
        row.append(scenario_accuracy)
        
        table.add_row(row)
    
    # æ·»åŠ æ€»è®¡è¡Œ
    total_row = ["æ€»è®¡"]
    overall_total_correct = 0
    overall_total_count = 0
    
    for model in model_names:
        all_correct = sum(correct for correct, total in stats[model].values())
        all_total = sum(total for correct, total in stats[model].values())
        if all_total == 0:
            total_accuracy = "N/A"
        else:
            total_accuracy = f"{all_correct/all_total*100:.1f}% ({all_correct}/{all_total})"
        total_row.append(total_accuracy)
        
        # ç´¯è®¡æ‰€æœ‰åœºæ™¯çš„æ€»æ­£ç¡®æ•°å’Œæ€»æµ‹è¯•æ•°
        overall_total_correct += all_correct
        overall_total_count += all_total
    
    # è®¡ç®—æ‰€æœ‰åœºæ™¯æ€»è®¡çš„æ€»è®¡
    if overall_total_count == 0:
        overall_accuracy = "N/A"
    else:
        overall_accuracy = f"{overall_total_correct/overall_total_count*100:.1f}% ({overall_total_correct}/{overall_total_count})"
    total_row.append(overall_accuracy)
    
    table.add_row(total_row)
    
    # è®¾ç½®è¡¨æ ¼æ ·å¼
    table.align = "l"  # å·¦å¯¹é½
    table.padding_width = 1  # å•å…ƒæ ¼å†…è¾¹è·
    
    # æ‰“å°è¡¨æ ¼
    print(table)
    print(f"{'='*100}")

if __name__ == "__main__":
    main()